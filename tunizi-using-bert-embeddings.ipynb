{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**: With this kernel, I wished to experiment with the effects of feature engineering on a model designed to minimize bias in toxicity detection using BERT Embeddings + LSTM. \n",
    "\n",
    "A series of functions used in the kernel are drawn from the original BERT Embeddings + LSTM kernel by Dieter https://www.kaggle.com/christofhenkel/bert-embeddings-lstm/. They are credited to the owner wherever possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm import tqdm, trange\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# pytorch bert imports\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertModel\n",
    "# keras imports\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import CuDNNLSTM, Activation, Dense, Dropout, Input, Embedding, concatenate, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from keras.layers import SpatialDropout1D, Dropout, add, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "import keras.layers as L\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tunizi-icompass', 'jigsaw-unintended-bias-in-toxicity-classification', 'bert-base-uncased']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../input\"))\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_PRETRAINED_DIR = '../input/bert-base-uncased'\n",
    "#INPUT_DIR = '../input/jigsaw-unintended-bias-in-toxicity-classification/'\n",
    "BERT_VOCAB_DIR = '../input/bert-base-uncased/vocab.txt'\n",
    "MAX_LENGTH = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the bert encoded training and test data\n",
    "train_data = pd.read_csv('../input/tunizi-icompass/tunizi_train.txt')\n",
    "test_data = train_data.sample(frac=0.3,random_state=200)\n",
    "train_data = train_data.drop(test_data.index)\n",
    "#test_data = pd.read_csv(INPUT_DIR + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21037</td>\n",
       "      <td>alah yara7me</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46442</td>\n",
       "      <td>brabi atini najah wahed amalta fi akaber korat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45602</td>\n",
       "      <td>bravo slouma walah rajel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30855</td>\n",
       "      <td>elboutoula ma nefhem chay</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19151</td>\n",
       "      <td>ma7laa zinkk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99054</td>\n",
       "      <td>sama7ha ejam3iya fi floussek kan te7eb leclub</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>87809</td>\n",
       "      <td>thawra 3amlouha kamchaa chbek batala dalsaltou...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39542</td>\n",
       "      <td>slouma chere president on vous soutient</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>83510</td>\n",
       "      <td>brass omik t3alam elbis walahi ent5abtik w tga...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29620</td>\n",
       "      <td>cha3b ca m3a slim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>35837</td>\n",
       "      <td>c est ça la force</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>86794</td>\n",
       "      <td>kon ana ngol lihom sa vous regarde pas</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>67947</td>\n",
       "      <td>wa inta wa side île koule tahante fransa</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19426</td>\n",
       "      <td>u best bro good work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75407</td>\n",
       "      <td>egsmoha 3asba</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30274</td>\n",
       "      <td>ani m3a slim ryahhi a3la5trou m3bbi mouch kima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>95428</td>\n",
       "      <td>etelha fi club w sayeb el 7okouma rak 7ata clu...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>87819</td>\n",
       "      <td>rahou 7abinek 3ala ca 7alik b3id ya si slim</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>71218</td>\n",
       "      <td>hhhhh la7léybi bayét y5amam meskin</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>71649</td>\n",
       "      <td>klemek hedhé me 3ad ynfa3né fi chey saben ezit...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>91854</td>\n",
       "      <td>vraiment ça fait mal de voir notre pays fi ydi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>99066</td>\n",
       "      <td>sameh meddeb tsawar wa7dik</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>49383</td>\n",
       "      <td>ismek salim inchalla dima salim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40677</td>\n",
       "      <td>netemano ya si slim madem andena chkoun fi fra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>49873</td>\n",
       "      <td>rabi m3ak winchala yasm3ou minik les faux poli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>86952</td>\n",
       "      <td>ya rfigi jek l3aw</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>22444</td>\n",
       "      <td>ah si slim bras omek alexis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>92757</td>\n",
       "      <td>enti ta7an w makech rajel n3mbouk w bou weldik...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>23569</td>\n",
       "      <td>jamila ménék george ya slouma d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>99621</td>\n",
       "      <td>kyfesh nahyy l vu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69960</th>\n",
       "      <td>26999</td>\n",
       "      <td>bellehi ya slouma choufenna kifech iajlou latr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69962</th>\n",
       "      <td>72015</td>\n",
       "      <td>ache amel fi snin menyaoui</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69963</th>\n",
       "      <td>85499</td>\n",
       "      <td>famma si slim we7ed bark</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69964</th>\n",
       "      <td>20923</td>\n",
       "      <td>allah yonser dinou</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69965</th>\n",
       "      <td>88189</td>\n",
       "      <td>abi a9felna m3a eljam3iy wenti daher fik akthe...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69967</th>\n",
       "      <td>48928</td>\n",
       "      <td>allah yar7mou ken ya3chak lefri9i</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69969</th>\n",
       "      <td>69601</td>\n",
       "      <td>amir ruisi slim achraf manak oi man asyadak ya...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69970</th>\n",
       "      <td>52344</td>\n",
       "      <td>tu as raison lotfi klamik na9ch 3al hjar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69972</th>\n",
       "      <td>78312</td>\n",
       "      <td>politique omoro y3ml iliy7b l mhom jm3ya ca</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69973</th>\n",
       "      <td>22319</td>\n",
       "      <td>rabi m3aaaaaaaaaaaaaaaaaaak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69974</th>\n",
       "      <td>18045</td>\n",
       "      <td>saha slouma ahna ouwled elghalia avec vous jus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69976</th>\n",
       "      <td>83204</td>\n",
       "      <td>jayaft l 3alouch sekina t3adiha mara bark</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69977</th>\n",
       "      <td>73846</td>\n",
       "      <td>haka fech fal7in kolkom kifkif ken enifa9 pari...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69980</th>\n",
       "      <td>42450</td>\n",
       "      <td>allah yarhmou w yna3mou</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69981</th>\n",
       "      <td>32018</td>\n",
       "      <td>omg congrats</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69983</th>\n",
       "      <td>33936</td>\n",
       "      <td>to9tol to9tol w bech n9olik 79i9a rak habaltho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69984</th>\n",
       "      <td>90552</td>\n",
       "      <td>o ena batal trah famechi wehed 7as biya kn nel...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69985</th>\n",
       "      <td>36036</td>\n",
       "      <td>wallah j ai remarqué</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69987</th>\n",
       "      <td>90945</td>\n",
       "      <td>shab3a botox</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69988</th>\n",
       "      <td>73411</td>\n",
       "      <td>hhh el tawa la fhmt sujet el gonya ye5i 5aneto...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69989</th>\n",
       "      <td>33593</td>\n",
       "      <td>big big boss de tout la tunisie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69990</th>\n",
       "      <td>20968</td>\n",
       "      <td>rabi yahfthek</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69992</th>\n",
       "      <td>40499</td>\n",
       "      <td>rabi yerhmou min ahel el djana inchaallah</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69993</th>\n",
       "      <td>19530</td>\n",
       "      <td>ala trifi rajol el mar7la</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69994</th>\n",
       "      <td>34914</td>\n",
       "      <td>maallem mr le president inchallah zina</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>28436</td>\n",
       "      <td>amazing i love it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>43069</td>\n",
       "      <td>ena raniiiiiiiiiii m3a eriahi ye3niii m3a jam3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>68137</td>\n",
       "      <td>hada maycharafech tounis</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>95143</td>\n",
       "      <td>leken rajlek haw et7adek wemcher we3mel inteviou</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>14668</td>\n",
       "      <td>rabi ya3atik kad kalbk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                               text  label\n",
       "0      21037                                       alah yara7me      1\n",
       "1      46442  brabi atini najah wahed amalta fi akaber korat...      1\n",
       "2      45602                           bravo slouma walah rajel      1\n",
       "3      30855                          elboutoula ma nefhem chay      1\n",
       "4      19151                                       ma7laa zinkk      1\n",
       "7      99054      sama7ha ejam3iya fi floussek kan te7eb leclub      0\n",
       "8      87809  thawra 3amlouha kamchaa chbek batala dalsaltou...     -1\n",
       "9      39542            slouma chere president on vous soutient      1\n",
       "10     83510  brass omik t3alam elbis walahi ent5abtik w tga...     -1\n",
       "11     29620                                  cha3b ca m3a slim      1\n",
       "13     35837                                  c est ça la force      1\n",
       "14     86794             kon ana ngol lihom sa vous regarde pas     -1\n",
       "16     67947           wa inta wa side île koule tahante fransa     -1\n",
       "17     19426                               u best bro good work      1\n",
       "18     75407                                      egsmoha 3asba     -1\n",
       "20     30274  ani m3a slim ryahhi a3la5trou m3bbi mouch kima...      1\n",
       "21     95428  etelha fi club w sayeb el 7okouma rak 7ata clu...     -1\n",
       "22     87819        rahou 7abinek 3ala ca 7alik b3id ya si slim     -1\n",
       "23     71218                 hhhhh la7léybi bayét y5amam meskin     -1\n",
       "24     71649  klemek hedhé me 3ad ynfa3né fi chey saben ezit...     -1\n",
       "25     91854  vraiment ça fait mal de voir notre pays fi ydi...     -1\n",
       "26     99066                         sameh meddeb tsawar wa7dik      0\n",
       "27     49383                    ismek salim inchalla dima salim      1\n",
       "28     40677  netemano ya si slim madem andena chkoun fi fra...      1\n",
       "29     49873  rabi m3ak winchala yasm3ou minik les faux poli...      1\n",
       "32     86952                                  ya rfigi jek l3aw     -1\n",
       "33     22444                        ah si slim bras omek alexis      1\n",
       "34     92757  enti ta7an w makech rajel n3mbouk w bou weldik...     -1\n",
       "35     23569                    jamila ménék george ya slouma d      1\n",
       "36     99621                                  kyfesh nahyy l vu      0\n",
       "...      ...                                                ...    ...\n",
       "69960  26999  bellehi ya slouma choufenna kifech iajlou latr...      1\n",
       "69962  72015                         ache amel fi snin menyaoui     -1\n",
       "69963  85499                           famma si slim we7ed bark     -1\n",
       "69964  20923                                 allah yonser dinou      1\n",
       "69965  88189  abi a9felna m3a eljam3iy wenti daher fik akthe...     -1\n",
       "69967  48928                  allah yar7mou ken ya3chak lefri9i      1\n",
       "69969  69601  amir ruisi slim achraf manak oi man asyadak ya...     -1\n",
       "69970  52344           tu as raison lotfi klamik na9ch 3al hjar      1\n",
       "69972  78312        politique omoro y3ml iliy7b l mhom jm3ya ca     -1\n",
       "69973  22319                        rabi m3aaaaaaaaaaaaaaaaaaak      1\n",
       "69974  18045  saha slouma ahna ouwled elghalia avec vous jus...      1\n",
       "69976  83204          jayaft l 3alouch sekina t3adiha mara bark     -1\n",
       "69977  73846  haka fech fal7in kolkom kifkif ken enifa9 pari...     -1\n",
       "69980  42450                            allah yarhmou w yna3mou      1\n",
       "69981  32018                                       omg congrats      1\n",
       "69983  33936  to9tol to9tol w bech n9olik 79i9a rak habaltho...      1\n",
       "69984  90552  o ena batal trah famechi wehed 7as biya kn nel...     -1\n",
       "69985  36036                               wallah j ai remarqué      1\n",
       "69987  90945                                       shab3a botox     -1\n",
       "69988  73411  hhh el tawa la fhmt sujet el gonya ye5i 5aneto...     -1\n",
       "69989  33593                    big big boss de tout la tunisie      1\n",
       "69990  20968                                      rabi yahfthek      1\n",
       "69992  40499          rabi yerhmou min ahel el djana inchaallah      1\n",
       "69993  19530                          ala trifi rajol el mar7la      1\n",
       "69994  34914             maallem mr le president inchallah zina      1\n",
       "69995  28436                                  amazing i love it      1\n",
       "69996  43069  ena raniiiiiiiiiii m3a eriahi ye3niii m3a jam3...      1\n",
       "69997  68137                           hada maycharafech tounis     -1\n",
       "69998  95143   leken rajlek haw et7adek wemcher we3mel inteviou     -1\n",
       "69999  14668                             rabi ya3atik kad kalbk      1\n",
       "\n",
       "[49000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37391</th>\n",
       "      <td>48417</td>\n",
       "      <td>bravo ama bouk miboun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14492</th>\n",
       "      <td>14774</td>\n",
       "      <td>haya si slim hana kolna em3ak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>32197</td>\n",
       "      <td>j aime et merci fi 5ater a7la jam3iya ca</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56041</th>\n",
       "      <td>50490</td>\n",
       "      <td>boutoula beb soui9a wel be9i maya3nina</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62963</th>\n",
       "      <td>42989</td>\n",
       "      <td>allah yara7mo inna lilleh wa inna ilayhi raji3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58887</th>\n",
       "      <td>22306</td>\n",
       "      <td>bravo si slim bon courage tous avec vous e rab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67183</th>\n",
       "      <td>52209</td>\n",
       "      <td>baby boy rabi i5aless wa7lek</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69841</th>\n",
       "      <td>94089</td>\n",
       "      <td>nsalfouk chwaya joueret</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66025</th>\n",
       "      <td>33319</td>\n",
       "      <td>mabrouuuuk rabi yhanikom très belle photo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65906</th>\n",
       "      <td>69993</td>\n",
       "      <td>ejoueur wino taw tiham 9alou fi parc l ihoud e...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42950</th>\n",
       "      <td>72512</td>\n",
       "      <td>bdit tda5el fi jam3itk lel music mte3k bsaraha...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55069</th>\n",
       "      <td>29823</td>\n",
       "      <td>bouzinek arwa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35161</th>\n",
       "      <td>80084</td>\n",
       "      <td>enchala la tsier ha lent5abet dawla de5la fi 7iet</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>83122</td>\n",
       "      <td>valeur mta3ik miboun</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>86913</td>\n",
       "      <td>maandnech mlaabia kbar surtout les attaquants</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57762</th>\n",
       "      <td>51996</td>\n",
       "      <td>mabrouk 3ala tounis 7orrasha loumanée wal 7amd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36192</th>\n",
       "      <td>22071</td>\n",
       "      <td>belle ya mariem</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63898</th>\n",
       "      <td>90833</td>\n",
       "      <td>ta3mlou lel 5ra mgharef</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33043</th>\n",
       "      <td>70007</td>\n",
       "      <td>bayen w tandid zeyed wlh zeyed kammlou jibou 9...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55594</th>\n",
       "      <td>44921</td>\n",
       "      <td>belahi majech ili ghardimaou</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26038</th>\n",
       "      <td>17706</td>\n",
       "      <td>baraka allahou fik khouya dja3far rabbi ikatar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62463</th>\n",
       "      <td>79196</td>\n",
       "      <td>tsami f roo7k syesi 3ad enti</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61170</th>\n",
       "      <td>77641</td>\n",
       "      <td>9anet 7 ta7ana</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14070</th>\n",
       "      <td>81149</td>\n",
       "      <td>chbeha rokbtek zarga a 5ra beyta 3la arb3a hhhh</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5576</th>\n",
       "      <td>67629</td>\n",
       "      <td>flous libiya</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29170</th>\n",
       "      <td>18810</td>\n",
       "      <td>mabrouk ya si slimm rahom edanadikk bech imout...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>40180</td>\n",
       "      <td>sluma ya kbir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18772</th>\n",
       "      <td>94675</td>\n",
       "      <td>hana wallina raj3in l ayamet ben 3li 3ad</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39088</th>\n",
       "      <td>48011</td>\n",
       "      <td>chnowa raykome fih</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59232</th>\n",
       "      <td>86268</td>\n",
       "      <td>ahawka atlouk</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23883</th>\n",
       "      <td>32538</td>\n",
       "      <td>slouma ya m3alam saieb a3lik eklemek em3ali in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32304</th>\n",
       "      <td>80895</td>\n",
       "      <td>nowab klo floss echa3b edaf3o 3la alerheb</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14842</th>\n",
       "      <td>95126</td>\n",
       "      <td>honnêtement lehou sahbi la amelli chahriya riehi</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36685</th>\n",
       "      <td>73632</td>\n",
       "      <td>lkolhom yjrou 3al korsi wel mouwaten zawali we...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67697</th>\n",
       "      <td>84744</td>\n",
       "      <td>opportuniste de merde sere9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50965</th>\n",
       "      <td>79375</td>\n",
       "      <td>bara ya3tek 3assba yazantour materba7ich assia...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>38984</td>\n",
       "      <td>m3ak king fi inti5abat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59201</th>\n",
       "      <td>22235</td>\n",
       "      <td>allahou akbar enna lellehi we enna ilayhi raji...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58255</th>\n",
       "      <td>19252</td>\n",
       "      <td>slim riahi kolna m3ah</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>96003</td>\n",
       "      <td>3zouza malhouta</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41229</th>\n",
       "      <td>50849</td>\n",
       "      <td>oui je crois</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25210</th>\n",
       "      <td>50513</td>\n",
       "      <td>mala 5edma ndhifa ya admin brabi winou essout ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12825</th>\n",
       "      <td>42001</td>\n",
       "      <td>peu de temp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>71783</td>\n",
       "      <td>eftah no9btek w taw nahkiw fel be9i ba3d</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51656</th>\n",
       "      <td>68276</td>\n",
       "      <td>mahouch schizo ama mnayek kifk bethabt hhh</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38626</th>\n",
       "      <td>74404</td>\n",
       "      <td>ekbes ro7ek wari basemtek fe jam3ya merina</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65436</th>\n",
       "      <td>97678</td>\n",
       "      <td>heykel sellami</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17293</th>\n",
       "      <td>22250</td>\n",
       "      <td>madam ena 9aset nchalah marbouha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69088</th>\n",
       "      <td>97684</td>\n",
       "      <td>hh aandi jem3tin nra f publication hedi kadee ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37442</th>\n",
       "      <td>75880</td>\n",
       "      <td>aha ye slim ye riahi rit eli 3malto el kol w 3...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41240</th>\n",
       "      <td>73743</td>\n",
       "      <td>fama 8alta aw fi lsection t3 erreponse bch man...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25782</th>\n",
       "      <td>83918</td>\n",
       "      <td>bara o5rj men kaleib tawa n as kol tasibk</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>73326</td>\n",
       "      <td>wlh rajil sa7bi ki jibitha brojla sada9ni moch...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52474</th>\n",
       "      <td>87472</td>\n",
       "      <td>maa monafe99 wnifa9 zayyyed</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42695</th>\n",
       "      <td>84827</td>\n",
       "      <td>hhhhh kili hiya miche 5amja</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25733</th>\n",
       "      <td>50461</td>\n",
       "      <td>men a7la ma 3edna fi tunis love u</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61192</th>\n",
       "      <td>42802</td>\n",
       "      <td>abir ya mhablethom zidhom hatta yetfalkou</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>31176</td>\n",
       "      <td>happy birthdays</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31479</th>\n",
       "      <td>50941</td>\n",
       "      <td>chwa9tni bech nitfarj 3lih</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24219</th>\n",
       "      <td>33066</td>\n",
       "      <td>sliem riya7i 5ier barcha o5rien w a7na mtakdie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                               text  label\n",
       "37391  48417                              bravo ama bouk miboun      1\n",
       "14492  14774                      haya si slim hana kolna em3ak      1\n",
       "2925   32197           j aime et merci fi 5ater a7la jam3iya ca      1\n",
       "56041  50490             boutoula beb soui9a wel be9i maya3nina      1\n",
       "62963  42989  allah yara7mo inna lilleh wa inna ilayhi raji3...      1\n",
       "58887  22306  bravo si slim bon courage tous avec vous e rab...      1\n",
       "67183  52209                       baby boy rabi i5aless wa7lek      1\n",
       "69841  94089                            nsalfouk chwaya joueret     -1\n",
       "66025  33319          mabrouuuuk rabi yhanikom très belle photo      1\n",
       "65906  69993  ejoueur wino taw tiham 9alou fi parc l ihoud e...     -1\n",
       "42950  72512  bdit tda5el fi jam3itk lel music mte3k bsaraha...     -1\n",
       "55069  29823                                      bouzinek arwa      1\n",
       "35161  80084  enchala la tsier ha lent5abet dawla de5la fi 7iet     -1\n",
       "1287   83122                               valeur mta3ik miboun     -1\n",
       "2537   86913      maandnech mlaabia kbar surtout les attaquants     -1\n",
       "57762  51996  mabrouk 3ala tounis 7orrasha loumanée wal 7amd...      1\n",
       "36192  22071                                    belle ya mariem      1\n",
       "63898  90833                            ta3mlou lel 5ra mgharef     -1\n",
       "33043  70007  bayen w tandid zeyed wlh zeyed kammlou jibou 9...     -1\n",
       "55594  44921                       belahi majech ili ghardimaou      1\n",
       "26038  17706  baraka allahou fik khouya dja3far rabbi ikatar...      1\n",
       "62463  79196                       tsami f roo7k syesi 3ad enti     -1\n",
       "61170  77641                                     9anet 7 ta7ana     -1\n",
       "14070  81149    chbeha rokbtek zarga a 5ra beyta 3la arb3a hhhh     -1\n",
       "5576   67629                                       flous libiya     -1\n",
       "29170  18810  mabrouk ya si slimm rahom edanadikk bech imout...      1\n",
       "3427   40180                                      sluma ya kbir      1\n",
       "18772  94675           hana wallina raj3in l ayamet ben 3li 3ad     -1\n",
       "39088  48011                                 chnowa raykome fih      1\n",
       "59232  86268                                      ahawka atlouk     -1\n",
       "...      ...                                                ...    ...\n",
       "23883  32538  slouma ya m3alam saieb a3lik eklemek em3ali in...      1\n",
       "32304  80895          nowab klo floss echa3b edaf3o 3la alerheb     -1\n",
       "14842  95126   honnêtement lehou sahbi la amelli chahriya riehi     -1\n",
       "36685  73632  lkolhom yjrou 3al korsi wel mouwaten zawali we...     -1\n",
       "67697  84744                        opportuniste de merde sere9     -1\n",
       "50965  79375  bara ya3tek 3assba yazantour materba7ich assia...     -1\n",
       "936    38984                             m3ak king fi inti5abat      1\n",
       "59201  22235  allahou akbar enna lellehi we enna ilayhi raji...      1\n",
       "58255  19252                              slim riahi kolna m3ah      1\n",
       "1795   96003                                    3zouza malhouta     -1\n",
       "41229  50849                                       oui je crois      1\n",
       "25210  50513  mala 5edma ndhifa ya admin brabi winou essout ...      1\n",
       "12825  42001                                        peu de temp      1\n",
       "5378   71783           eftah no9btek w taw nahkiw fel be9i ba3d     -1\n",
       "51656  68276         mahouch schizo ama mnayek kifk bethabt hhh     -1\n",
       "38626  74404         ekbes ro7ek wari basemtek fe jam3ya merina     -1\n",
       "65436  97678                                     heykel sellami      0\n",
       "17293  22250                   madam ena 9aset nchalah marbouha      1\n",
       "69088  97684  hh aandi jem3tin nra f publication hedi kadee ...      0\n",
       "37442  75880  aha ye slim ye riahi rit eli 3malto el kol w 3...     -1\n",
       "41240  73743  fama 8alta aw fi lsection t3 erreponse bch man...     -1\n",
       "25782  83918          bara o5rj men kaleib tawa n as kol tasibk     -1\n",
       "4755   73326  wlh rajil sa7bi ki jibitha brojla sada9ni moch...     -1\n",
       "52474  87472                        maa monafe99 wnifa9 zayyyed     -1\n",
       "42695  84827                        hhhhh kili hiya miche 5amja     -1\n",
       "25733  50461                  men a7la ma 3edna fi tunis love u      1\n",
       "61192  42802          abir ya mhablethom zidhom hatta yetfalkou      1\n",
       "2981   31176                                    happy birthdays      1\n",
       "31479  50941                         chwa9tni bech nitfarj 3lih      1\n",
       "24219  33066  sliem riya7i 5ier barcha o5rien w a7na mtakdie...      1\n",
       "\n",
       "[21000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Feature Engineering for the training data\\nregex = re.compile('[@_!#$%^&*()<>?/\\\\|}{~:]')\\ntrain_data['capitals'] = train_data['text'].apply(lambda x: sum(1 for c in x if c.isupper()))\\ntrain_data['exclamation_points'] = train_data['comment_text'].apply(lambda x: len(regex.findall(x)))\\ntrain_data['total_length'] = train_data['comment_text'].apply(len)\\n\\n# Feature Engineering for the test data\\ntest_data['capitals'] = test_data['comment_text'].apply(lambda x: sum(1 for c in x if c.isupper()))\\ntest_data['exclamation_points'] = test_data['comment_text'].apply(lambda x: len(regex.findall(x)))\\ntest_data['total_length'] = test_data['comment_text'].apply(len)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Feature Engineering for the training data\n",
    "regex = re.compile('[@_!#$%^&*()<>?/\\|}{~:]')\n",
    "train_data['capitals'] = train_data['text'].apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "train_data['exclamation_points'] = train_data['comment_text'].apply(lambda x: len(regex.findall(x)))\n",
    "train_data['total_length'] = train_data['comment_text'].apply(len)\n",
    "\n",
    "# Feature Engineering for the test data\n",
    "test_data['capitals'] = test_data['comment_text'].apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "test_data['exclamation_points'] = test_data['comment_text'].apply(lambda x: len(regex.findall(x)))\n",
    "test_data['total_length'] = test_data['comment_text'].apply(len)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"new_features = ['capitals','exclamation_points','total_length']\"\"\"\n",
    "identity_columns = ['male','female','homosexual_gay_or_lesbian','christian','jewish','muslim',\n",
    "                    'black','white','psychiatric_or_mental_illness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Customizing the weights\n",
    "y_ids= (train_data[identity_columns] >= 0.5).astype(int).values\n",
    "# Overall\n",
    "weights = np.ones((len(train_data),)) / 4\n",
    "# Subgroup\n",
    "weights += (train_data[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) / 4\n",
    "# Background Positive, Subgroup Negative\n",
    "weights += (( (train_data['target'].values>=0.5).astype(bool).astype(np.int) +\n",
    "   (train_data[identity_columns].fillna(0).values<0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) / 4\n",
    "# Background Negative, Subgroup Positive\n",
    "weights += (( (train_data['target'].values<0.5).astype(bool).astype(np.int) +\n",
    "   (train_data[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) / 4\n",
    "loss_weight = 1.0 / weights.mean()\"\"\"\n",
    "\n",
    "y_train = np.vstack([(train_data['label'].values).astype(np.int)]).T\n",
    "y_aux_train = train_data[['label']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Conversion of continuous target columns to categorical\\nfor column in identity_columns + ['target']:\\n    train_data[column]= np.where(train_data[column] >= 0.5, True, False)\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Conversion of continuous target columns to categorical\n",
    "for column in identity_columns + ['target']:\n",
    "    train_data[column]= np.where(train_data[column] >= 0.5, True, False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_preprocessing(text):\n",
    "    filter_char = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r“”’\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—'\n",
    "    text = text.lower()\n",
    "    text = text.replace(filter_char,'')\n",
    "    text = text.replace('[^a-zA-Z0-9 ]', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['text'] = train_data['text'].apply(nlp_preprocessing)\n",
    "test_data['text'] = test_data['text'].apply(nlp_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising BERT tokenizer\n",
    "tokenizer = BertTokenizer(vocab_file='../input/bert-base-uncased/vocab.txt')\n",
    "def tokenization(row):\n",
    "    row = tokenizer.tokenize(row)\n",
    "    row = tokenizer.convert_tokens_to_ids(row)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['text'] = train_data['text'].apply(tokenization)\n",
    "test_data['text'] = test_data['text'].apply(tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_ids(doc):\n",
    "    doc = [str(i) for i in doc]\n",
    "    return ' '.join(doc)\n",
    "train_data['text'] = train_data['text'].apply(string_ids)\n",
    "test_data['text'] = test_data['text'].apply(string_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49000it [00:00, 63278.18it/s]\n",
      "21000it [00:00, 64399.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.zeros((train_data.shape[0],MAX_LENGTH),dtype=np.int)\n",
    "\n",
    "for i,ids in tqdm(enumerate(list(train_data['text']))):\n",
    "    input_ids = [int(i) for i in ids.split()[:MAX_LENGTH]]\n",
    "    inp_len = len(input_ids)\n",
    "    x_train[i,:inp_len] = np.array(input_ids)\n",
    "    \n",
    "x_test = np.zeros((test_data.shape[0],MAX_LENGTH),dtype=np.int)\n",
    "\n",
    "for i,ids in tqdm(enumerate(list(test_data['text']))):\n",
    "\n",
    "    input_ids = [int(i) for i in ids.split()[:MAX_LENGTH]]\n",
    "    inp_len = len(input_ids)\n",
    "    x_test[i,:inp_len] = np.array(input_ids)\n",
    "    \n",
    "with open('temporary.pickle', mode='wb') as f:\n",
    "    pickle.dump(x_test, f) # use temporary file to reduce memory\n",
    "\n",
    "# Removing extra variables to free up the memory\n",
    "del x_test\n",
    "del test_data\n",
    "del train_data\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_func(y_true, y_preds):\n",
    "    loss = binary_crossentropy(K.reshape(y_true[:,0],(-1,1)), y_preds) * y_true[:,1]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embed_matrix():\n",
    "    bert = BertModel.from_pretrained(BERT_PRETRAINED_DIR)\n",
    "    bert_embeddings = list(bert.children())[0]\n",
    "    bert_word_embeddings = list(bert_embeddings.children())[0]\n",
    "    mat = bert_word_embeddings.weight.data.numpy()\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01018257, -0.06154883, -0.02649689, ..., -0.01985357,\n",
       "        -0.03720997, -0.00975152],\n",
       "       [-0.01170495, -0.06002603, -0.03233192, ..., -0.01681456,\n",
       "        -0.04009988, -0.0106634 ],\n",
       "       [-0.01975381, -0.06273633, -0.03262176, ..., -0.01650258,\n",
       "        -0.04198876, -0.00323178],\n",
       "       ...,\n",
       "       [-0.02176224, -0.0556396 , -0.01346345, ..., -0.00432698,\n",
       "        -0.0151355 , -0.02489496],\n",
       "       [-0.04617237, -0.05647721, -0.00192082, ...,  0.01568751,\n",
       "        -0.01387033, -0.00945213],\n",
       "       [ 0.00145601, -0.08208051, -0.01597912, ..., -0.00811687,\n",
       "        -0.04746607,  0.07527421]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = get_bert_embed_matrix()\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(embedding_matrix, num_aux_targets):\n",
    "    '''\n",
    "    credits go to: https://www.kaggle.com/thousandvoices/simple-lstm/\n",
    "    '''\n",
    "    words = Input(shape=(MAX_LENGTH,))\n",
    "    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n",
    "    x = SpatialDropout1D(0.5)(x)\n",
    "    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n",
    "    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n",
    "\n",
    "    hidden = concatenate([GlobalMaxPooling1D()(x),GlobalAveragePooling1D()(x),])\n",
    "    hidden = add([hidden, Dense(HIDDEN_UNITS, activation='relu')(hidden)])\n",
    "    hidden = add([hidden, Dense(HIDDEN_UNITS, activation='relu')(hidden)])\n",
    "    result = Dense(1, activation='sigmoid')(hidden)\n",
    "    aux_result = Dense(num_aux_targets, activation='sigmoid')(hidden)\n",
    "    \n",
    "    model = Model(inputs=words, outputs=[result, aux_result])\n",
    "    model.compile(loss=[custom_loss_func,'binary_crossentropy'],\n",
    "                  optimizer=Adam(lr = 0.001))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_idx, val_idx = train_test_split(list(range(len(x_train))) ,test_size = 0.05, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46550 samples, validate on 2450 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument: slice index 1 of dimension 1 out of bounds.\n\t [[{{node loss/dense_3_loss/strided_slice_1}}]]\n\t [[loss/dense_4_loss/Mean_3/_253]]\n  (1) Invalid argument: slice index 1 of dimension 1 out of bounds.\n\t [[{{node loss/dense_3_loss/strided_slice_1}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9fa0d920a8e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m               callbacks=[LearningRateScheduler(lambda epoch: 1e-3 * (0.6 ** epoch))])\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temporary.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: slice index 1 of dimension 1 out of bounds.\n\t [[{{node loss/dense_3_loss/strided_slice_1}}]]\n\t [[loss/dense_4_loss/Mean_3/_253]]\n  (1) Invalid argument: slice index 1 of dimension 1 out of bounds.\n\t [[{{node loss/dense_3_loss/strided_slice_1}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "LSTM_UNITS = 128\n",
    "HIDDEN_UNITS = 4 * LSTM_UNITS\n",
    "model_predictions = []\n",
    "model_val_preds = []\n",
    "weights = []\n",
    "\n",
    "# Model Training and Prediction Phase\n",
    "model = build_model(embedding_matrix, y_aux_train.shape[-1])\n",
    "for epoch in range(epochs):\n",
    "    model.fit(x_train[tr_idx],[y_train[tr_idx], y_aux_train[tr_idx]],\n",
    "              validation_data = (x_train[val_idx],[y_train[val_idx], y_aux_train[val_idx]]),\n",
    "              batch_size=512,\n",
    "              epochs=1,\n",
    "              verbose=1,\n",
    "              callbacks=[LearningRateScheduler(lambda epoch: 1e-3 * (0.6 ** epoch))])\n",
    "    with open('temporary.pickle', mode='rb') as f:\n",
    "        x_test = pickle.load(f) \n",
    "    model_predictions.append(model.predict(x_test, batch_size=2048)[0].flatten())\n",
    "    model_val_preds.append(model.predict(x_train[val_idx], batch_size=2048)[0].flatten())\n",
    "    del x_test\n",
    "    gc.collect()\n",
    "    weights.append(2 ** epoch)\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "Weights sum to zero, can't be normalized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a54d5ca1bb5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_val_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             raise ZeroDivisionError(\n\u001b[0;32m--> 422\u001b[0;31m                 \"Weights sum to zero, can't be normalized\")\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: Weights sum to zero, can't be normalized"
     ]
    }
   ],
   "source": [
    "val_preds = np.average(model_val_preds, weights = weights, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a676e1f2c8e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_auc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mget_total_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_preds' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\" Following section is drawn from a set of functions used on https://www.kaggle.com/christofhenkel/bert-embeddings-lstm/ \"\"\"\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_s_auc(y_true,y_pred,y_identity):\n",
    "    mask = y_identity==1\n",
    "    try:\n",
    "        s_auc = roc_auc_score(y_true[mask],y_pred[mask])\n",
    "    except:\n",
    "        s_auc = 1\n",
    "    return s_auc\n",
    "\n",
    "def get_bspn_auc(y_true,y_pred,y_identity):\n",
    "    mask = (y_identity==1) & (y_true==1) | (y_identity==0) & (y_true==0)\n",
    "    try:\n",
    "        bspn_auc = roc_auc_score(y_true[mask],y_pred[mask])\n",
    "    except:\n",
    "        bspn_auc = 1\n",
    "    return bspn_auc\n",
    "\n",
    "def get_bpsn_auc(y_true,y_pred,y_identity):\n",
    "    mask = (y_identity==1) & (y_true==0) | (y_identity==0) & (y_true==1)\n",
    "    try:\n",
    "        bpsn_auc = roc_auc_score(y_true[mask],y_pred[mask])\n",
    "    except:\n",
    "        bpsn_auc = 1\n",
    "    return bpsn_auc\n",
    "\n",
    "def get_total_auc(y_true,y_pred,y_identities):\n",
    "    N = y_identities.shape[1]\n",
    "    \n",
    "    saucs = np.array([get_s_auc(y_true,y_pred,y_identities[:,i]) for i in range(N)])\n",
    "    bpsns = np.array([get_bpsn_auc(y_true,y_pred,y_identities[:,i]) for i in range(N)])\n",
    "    bspns = np.array([get_bspn_auc(y_true,y_pred,y_identities[:,i]) for i in range(N)])\n",
    "\n",
    "    M_s_auc = np.power(np.mean(np.power(saucs, -5)),1/-5)\n",
    "    M_bpsns_auc = np.power(np.mean(np.power(bpsns, -5)),1/-5)\n",
    "    M_bspns_auc = np.power(np.mean(np.power(bspns, -5)),1/-5)\n",
    "    r_auc = roc_auc_score(y_true,y_pred)\n",
    "    \n",
    "    total_auc = M_s_auc + M_bpsns_auc + M_bspns_auc + r_auc\n",
    "    total_auc/= 4\n",
    "\n",
    "    return total_auc\n",
    "\n",
    "get_total_auc(y_train[val_idx][:,0],val_preds,y_ids[val_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission Stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "Weights sum to zero, can't be normalized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c7bf1bce1e8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate average predictions for the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             raise ZeroDivisionError(\n\u001b[0;32m--> 422\u001b[0;31m                 \"Weights sum to zero, can't be normalized\")\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: Weights sum to zero, can't be normalized"
     ]
    }
   ],
   "source": [
    "# Calculate average predictions for the model\n",
    "predictions = np.average(model_predictions, weights=weights, axis=0)\n",
    "\n",
    "df_submission = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\n",
    "df_submission.drop(['comment_text'],axis = 1, inplace = True)\n",
    "df_submission['prediction'] = predictions\n",
    "df_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
